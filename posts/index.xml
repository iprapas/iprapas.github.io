<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Ioannis Prapas</title><link>https://iprapas.github.io/posts/</link><description>Recent content in Posts on Ioannis Prapas</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 29 May 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://iprapas.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Easiest way to use Python virtual environments</title><link>https://iprapas.github.io/posts/python-virtualenv/</link><pubDate>Fri, 29 May 2020 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/python-virtualenv/</guid><description>Disclaimer: I know what you are thinking &amp;ldquo;That title is a clickbait&amp;rdquo;. I feel a little bit bad about it. But on second thought, I don&amp;rsquo;t have regrets.
It is the easiest way I know and I dare you to leave a comment if you know a better way.
What are virtual environments Instead of adding new python packages to your system installation, you add them to a virtual installation&amp;rsquo;s site-packages.</description></item><item><title>Remote Jupyter notebook locally over ssh gate</title><link>https://iprapas.github.io/posts/remote-jupyter-notebook/</link><pubDate>Mon, 25 May 2020 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/remote-jupyter-notebook/</guid><description>Problem I have encountered several times this problem:
Me: I want a nice interface to run python code in a remote machine.
Jupyter Notebook: I am here for you.
SSH Gate: I&amp;rsquo;ll make things trickier.
Well, here is the guide to setup a jupyter notebook server in a remote machine and connect to it, even if you need to pass through an ssh gate.
This guide is for UNIX-like systems and has been tested on Ubuntu 18.</description></item><item><title>Spam Classification with Spark MLLib</title><link>https://iprapas.github.io/posts/mllib-classification/</link><pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/mllib-classification/</guid><description>Disclaimer: This blog post will present my solution to an exercise of the Scalable Data Science offered by TU Berlin in winter semester 2019-2020.
Introduction In this exercise, we had to learn a model to classify spam, nospam SMS messages. We were given the SMS Spam Collection Data Set, split in 4 files:
training_spam.txt
training_nospam.txt
testing_spam.txt
testing_spam.txt
The goal is to train a model on the contents of the training* files and use it to predict the testing*.</description></item><item><title>What is a Data Warehouse?</title><link>https://iprapas.github.io/posts/data-warehouse-intro/</link><pubDate>Fri, 12 Apr 2019 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/data-warehouse-intro/</guid><description>It helps to contrast the Data Warehouse to something you already know. So, let&amp;rsquo;s compare to a traditional Database.
Database (DB) VS Data Warehouse (DW) Forgive me for somehow simplifying and not accounting for the diversity out there, but I&amp;rsquo;ll sum this up to the following:
Databases are used for OnLine Transaction Processing (OLTP); that is for transactions that historically aim to optimize the support of daily business operations (transactions), while ensuring concurrent access and data consistency through ACID (for NoSQL maybe forget that last part).</description></item><item><title>Creating a Recommender System with a Graph DB (Neo4j)</title><link>https://iprapas.github.io/posts/neo4j-recommender/</link><pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/neo4j-recommender/</guid><description>This work is based on a project on the Semantic Data Management course I followed in Barcelona in the summer semester 2018-2019 as part of the BDMA Erasmus Mundus Master program.
It was done in collaboration with my lab mate Elena Ouro. Code available on github.
The problem description The problem is to design and implement a graph database for publishing academic literature. Then, to use an algorithm based on pagerank to suggest reviewers for papers of the database community.</description></item><item><title>How I reached top 2% in my first kaggle competition</title><link>https://iprapas.github.io/posts/kaggle-plasticc/</link><pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/kaggle-plasticc/</guid><description>Just before the competition, my experience with data science was:
From online courses, with most notable one the Coursera course on Machine Learning with Andrew NG. Some others included Scalable Machine Learning with Spark, and Computational Thinking and Data Science with Python. From my thesis, which had a limited focus on deep learning. I lacked, however, any practical experience and although I wanted to join kaggle competitions in the past, I did not really know how to start.</description></item></channel></rss>