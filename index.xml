<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ioannis Prapas</title><link>https://iprapas.github.io/</link><description>Recent content on Ioannis Prapas</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sat, 01 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://iprapas.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>AI for Good Workshop, Wildfire Forecasting at Different Spatiotemporal Scales</title><link>https://iprapas.github.io/posts/ai4good_talk/</link><pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/ai4good_talk/</guid><description>I am happy to present in a very interesting workshop on July 5th about The role of AI in tackling climate change and its impacts: from science to early warning My presentation is on the use of deep learning to forecast wildfires at different spatio-temporal scales.
Title: Wildfire danger forecasting at different spatio-temporal scales
Abstract: Climate change exacerbates the occurence of extreme droughts and heatwaves, increasing the frequency and intensity of large wildfires across the globe.</description></item><item><title>Webinar: Fighting wildfires with AI-powered insights</title><link>https://iprapas.github.io/posts/itu-talk-2023/</link><pubDate>Sat, 01 Apr 2023 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/itu-talk-2023/</guid><description>Happy to present in the ITU Webinar on &amp;ldquo;Fighting wildfires with AI-powered insights&amp;rdquo; on Aprin 19th.
My presentation is on &amp;ldquo;Deep learning for wildfire danger forecasting at different spatio-temporal scales&amp;rdquo;.
Presentation | Recording
https://www.itu.int/en/ITU-T/webinars/20230419/Pages/default.aspx</description></item><item><title>Deep Learning for Daily Wildfire Danger Forecasting (NeurIPS 2021)</title><link>https://iprapas.github.io/posts/hadrai-neurips-poster/</link><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/hadrai-neurips-poster/</guid><description>Happy to present our publication in the NeurIPS 2021 at the workshop on Artificial Intelligence for Humanitarian Assistance and Disaster Response (hadr.ai).
Check out the poster below that sums up what we have done.
And if you are more interested read our paper or send me a message.</description></item><item><title>Fresh publication: Continuous Deployment of Deep Learning models</title><link>https://iprapas.github.io/posts/lwda2021-article/</link><pubDate>Mon, 30 Aug 2021 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/lwda2021-article/</guid><description>Check my research article presentation on &amp;ldquo;Continuous Training and Deployment of Deep Learning models&amp;rdquo; at LWDA 2021 - Wednesday, Sep 1st 14:00-14:20 CET. It is free to attend, you only need to register here.
This article is based on the thesis I did for the completion of my studies in the Big Data Management and Analytics (BDMA) Erasmus Mundus MSc.
Abstract
Deep Learning (DL) has consistently surpassed other Machine Learning methods and achieved state-of-the-art performance in multiple cases.</description></item><item><title>Intro to geospatial data analysis with Python - learndatasci.com</title><link>https://iprapas.github.io/posts/learndatasci-geospatial-pt1/</link><pubDate>Tue, 20 Jul 2021 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/learndatasci-geospatial-pt1/</guid><description>Check my new article - Analyze Geospatial Data in Python: GeoPandas and Shapely in learndatasci.com.
This is the first part of a series of 3 articles around geospatial data analysis with Python.</description></item><item><title>Applied Dimensionality Reduction - learndatasci.com</title><link>https://iprapas.github.io/posts/learndatasci-dim-reduction/</link><pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/learndatasci-dim-reduction/</guid><description>Check my new article - Applied Dimensionality Reduction in learndatasci.com.</description></item><item><title>Easiest way to use Python virtual environments</title><link>https://iprapas.github.io/posts/python-virtualenv/</link><pubDate>Fri, 29 May 2020 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/python-virtualenv/</guid><description>Disclaimer: I know what you are thinking &amp;ldquo;That title is a clickbait&amp;rdquo;. I feel a little bit bad about it. But on second thought, I don&amp;rsquo;t have regrets.
It is the easiest way I know and I dare you to leave a comment if you know a better way.
What are virtual environments Instead of adding new python packages to your system installation, you add them to a virtual installation&amp;rsquo;s site-packages.</description></item><item><title>Remote Jupyter notebook locally over ssh gate</title><link>https://iprapas.github.io/posts/remote-jupyter-notebook/</link><pubDate>Mon, 25 May 2020 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/remote-jupyter-notebook/</guid><description>Problem I have encountered several times this problem:
Me: I want a nice interface to run python code in a remote machine.
Jupyter Notebook: I am here for you.
SSH Gate: I&amp;rsquo;ll make things trickier.
Well, here is the guide to setup a jupyter notebook server in a remote machine and connect to it, even if you need to pass through an ssh gate.
This guide is for UNIX-like systems and has been tested on Ubuntu 18.</description></item><item><title>Spam Classification with Spark MLLib</title><link>https://iprapas.github.io/posts/mllib-classification/</link><pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/mllib-classification/</guid><description>Disclaimer: This blog post will present my solution to an exercise of the Scalable Data Science offered by TU Berlin in winter semester 2019-2020.
Introduction In this exercise, we had to learn a model to classify spam, nospam SMS messages. We were given the SMS Spam Collection Data Set, split in 4 files:
training_spam.txt
training_nospam.txt
testing_spam.txt
testing_spam.txt
The goal is to train a model on the contents of the training* files and use it to predict the testing*.</description></item><item><title>What is a Data Warehouse?</title><link>https://iprapas.github.io/posts/data-warehouse-intro/</link><pubDate>Fri, 12 Apr 2019 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/data-warehouse-intro/</guid><description>It helps to contrast the Data Warehouse to something you already know. So, let&amp;rsquo;s compare to a traditional Database.
Database (DB) VS Data Warehouse (DW) Forgive me for somehow simplifying and not accounting for the diversity out there, but I&amp;rsquo;ll sum this up to the following:
Databases are used for OnLine Transaction Processing (OLTP); that is for transactions that historically aim to optimize the support of daily business operations (transactions), while ensuring concurrent access and data consistency through ACID (for NoSQL maybe forget that last part).</description></item><item><title>Creating a Recommender System with a Graph DB (Neo4j)</title><link>https://iprapas.github.io/posts/neo4j-recommender/</link><pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/neo4j-recommender/</guid><description>This work is based on a project on the Semantic Data Management course I followed in Barcelona in the summer semester 2018-2019 as part of the BDMA Erasmus Mundus Master program.
It was done in collaboration with my lab mate Elena Ouro. Code available on github.
The problem description The problem is to design and implement a graph database for publishing academic literature. Then, to use an algorithm based on pagerank to suggest reviewers for papers of the database community.</description></item><item><title>How I reached top 2% in my first kaggle competition</title><link>https://iprapas.github.io/posts/kaggle-plasticc/</link><pubDate>Thu, 10 Jan 2019 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/posts/kaggle-plasticc/</guid><description>Just before the competition, my experience with data science was:
From online courses, with most notable one the Coursera course on Machine Learning with Andrew NG. Some others included Scalable Machine Learning with Spark, and Computational Thinking and Data Science with Python. From my thesis, which had a limited focus on deep learning. I lacked, however, any practical experience and although I wanted to join kaggle competitions in the past, I did not really know how to start.</description></item><item><title>About me and this blog</title><link>https://iprapas.github.io/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/about/</guid><description>Professionally speaking, I am a Software Engineer with an interest in Machine Learning and Big Data. I love coding and designing algorithms. As a person, I like to explore the world and learn about science and humanity. I am especially interested in astrophysics, neuroscience, biology and life sciences. I like spending time with friends, watching movies, playing board games and doing sports. Deep down, I am just like you; an insignificant human being.</description></item><item><title>Links</title><link>https://iprapas.github.io/links/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://iprapas.github.io/links/</guid><description>Personal Plasticc Kaggle Competition (blog post | report | slides)
Towards Human Activity Reasoning with Computational Logic and Deep Learning (SETN 2018). (preprint | paper)
Misc interesting Good music (John Frusciante - Before The Beginning)
Inspiring speech (Carl Sagan - Pale Blue Dot)
Great article (Wait But Why - Artificial Intelligence Revolution)</description></item></channel></rss>